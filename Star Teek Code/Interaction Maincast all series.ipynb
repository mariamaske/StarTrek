{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "53e03f97",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from collections import Counter\n",
    "import json\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1e6d78f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign path variable\n",
    "path = '/Users/mariamaske/Star Trek Analysis/Data/Cleaned Data'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a742eda3",
   "metadata": {},
   "source": [
    "## TAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fad0463c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Series               Dialogue1 Dialogue2  Count\n",
      "109    TAS                    KIRK     SPOCK     13\n",
      "156    TAS                   SPOCK      SULU      7\n",
      "162    TAS                    SULU     UHURA      7\n",
      "138    TAS                   MCCOY     SPOCK      6\n",
      "106    TAS                    KIRK     MCCOY      4\n",
      "..     ...                     ...       ...    ...\n",
      "155    TAS                    SORD     SPOCK      1\n",
      "157    TAS                   SPOCK     TCHAR      1\n",
      "158    TAS                   SPOCK    THELIN      1\n",
      "160    TAS  SPOCK: Ready, Captain.    WESLEY      1\n",
      "161    TAS                  STAVOS     UHURA      1\n",
      "\n",
      "[163 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "def extract_and_filter_interactions(json_file_path, specific_series, lines_threshold=2):\n",
    "    # Read data from the JSON file\n",
    "    with open(json_file_path, 'r') as file:\n",
    "        json_data = json.load(file)\n",
    "    # Extract interactions with series and episode information\n",
    "    interactions = []\n",
    "    for series_key, series_data in json_data.items():\n",
    "        if series_key == specific_series:\n",
    "            for character, dialogues in series_data.items():\n",
    "                # Ensure there are at least two dialogues for each character\n",
    "                if len(dialogues) >= lines_threshold:\n",
    "                    # Convert dialogues to strings\n",
    "                    dialogues = [str(dialogue) for dialogue in dialogues]\n",
    "\n",
    "                    # Create pairs of consecutive dialogues with series information\n",
    "                    for i in range(len(dialogues) - 1):\n",
    "                        # Sort the dialogues to ensure consistent order\n",
    "                        sorted_dialogues = sorted([dialogues[i], dialogues[i + 1]])\n",
    "\n",
    "                        interaction = (series_key, sorted_dialogues[0], sorted_dialogues[1])\n",
    "                        interactions.append(interaction)\n",
    "\n",
    "    # Count occurrences of interactions\n",
    "    interaction_counts = Counter(interactions)\n",
    "\n",
    "    # Convert the result to a DataFrame\n",
    "    df = pd.DataFrame(list(interaction_counts.items()), columns=['Interaction', 'Count'])\n",
    "\n",
    "    # Split the 'Interaction' column into 'Series', 'Dialogue1', and 'Dialogue2'\n",
    "    df[['Series', 'Dialogue1', 'Dialogue2']] = pd.DataFrame(df['Interaction'].tolist(), index=df.index)\n",
    "\n",
    "    # Drop the original 'Interaction' column\n",
    "    df.drop(columns=['Interaction'], inplace=True)\n",
    "\n",
    "    # Reorder columns\n",
    "    df = df[['Series', 'Dialogue1', 'Dialogue2', 'Count']]\n",
    "\n",
    "    # Group by the combined dialogues and sum the counts\n",
    "    df_combined = df.groupby(['Series', 'Dialogue1', 'Dialogue2']).agg({'Count': 'sum'}).reset_index()\n",
    "\n",
    "    # Sort by series, interaction, and count in descending order\n",
    "    df_combined.sort_values(by=['Series', 'Count'], ascending=[True, False], inplace=True)\n",
    "\n",
    "    # Filter the DataFrame for a specific series\n",
    "    filtered_df = df_combined.loc[df_combined['Series'] == specific_series]\n",
    "\n",
    "    return filtered_df\n",
    "\n",
    "# Example usage with lines_threshold set to 3\n",
    "json_file_path = '/Users/mariamaske/Star Trek Analysis/Data/StarTrekDialogue.json'\n",
    "specific_series = 'TAS'\n",
    "lines_threshold = 5\n",
    "result_df = extract_and_filter_interactions(json_file_path, specific_series, lines_threshold)\n",
    "\n",
    "# Print the final result\n",
    "print(result_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b251869e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace 'Dialogue1', 'Dialogue2', and 'Count' with the actual column names in your dataset\n",
    "allowed_dialogue1_values = ['KIRK', 'SPOCK', 'MCCOY', 'CHEKOV', 'SCOTT', 'SULU', 'UHURA', 'CHAPEL']  # Replace with the specific values you're interested in for 'Dialogue1'\n",
    "allowed_dialogue2_values = ['KIRK', 'SPOCK', 'MCCOY', 'CHEKOV', 'SCOTT', 'SULU', 'UHURA', 'CHAPEL']  # Replace with the specific values you're interested in for 'Dialogue2'\n",
    "\n",
    "filtered_df = result_df[\n",
    "    (result_df['Dialogue1'].isin(allowed_dialogue1_values)) & \n",
    "    (result_df['Dialogue2'].isin(allowed_dialogue2_values)) & \n",
    "    (result_df['Count'] >= 1)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f2a0f719",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Series</th>\n",
       "      <th>Dialogue1</th>\n",
       "      <th>Dialogue2</th>\n",
       "      <th>Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>TAS</td>\n",
       "      <td>KIRK</td>\n",
       "      <td>SPOCK</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>TAS</td>\n",
       "      <td>SPOCK</td>\n",
       "      <td>SULU</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>TAS</td>\n",
       "      <td>SULU</td>\n",
       "      <td>UHURA</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>TAS</td>\n",
       "      <td>MCCOY</td>\n",
       "      <td>SPOCK</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>TAS</td>\n",
       "      <td>KIRK</td>\n",
       "      <td>MCCOY</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>TAS</td>\n",
       "      <td>KIRK</td>\n",
       "      <td>SCOTT</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>TAS</td>\n",
       "      <td>MCCOY</td>\n",
       "      <td>SCOTT</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>TAS</td>\n",
       "      <td>SCOTT</td>\n",
       "      <td>SULU</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>TAS</td>\n",
       "      <td>SCOTT</td>\n",
       "      <td>UHURA</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>TAS</td>\n",
       "      <td>SPOCK</td>\n",
       "      <td>UHURA</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>TAS</td>\n",
       "      <td>CHAPEL</td>\n",
       "      <td>SCOTT</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>TAS</td>\n",
       "      <td>MCCOY</td>\n",
       "      <td>UHURA</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>TAS</td>\n",
       "      <td>SCOTT</td>\n",
       "      <td>SPOCK</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>TAS</td>\n",
       "      <td>KIRK</td>\n",
       "      <td>UHURA</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>TAS</td>\n",
       "      <td>MCCOY</td>\n",
       "      <td>SULU</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>TAS</td>\n",
       "      <td>CHAPEL</td>\n",
       "      <td>MCCOY</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Series Dialogue1 Dialogue2  Count\n",
       "109    TAS      KIRK     SPOCK     13\n",
       "156    TAS     SPOCK      SULU      7\n",
       "162    TAS      SULU     UHURA      7\n",
       "138    TAS     MCCOY     SPOCK      6\n",
       "106    TAS      KIRK     MCCOY      4\n",
       "108    TAS      KIRK     SCOTT      4\n",
       "137    TAS     MCCOY     SCOTT      4\n",
       "150    TAS     SCOTT      SULU      4\n",
       "152    TAS     SCOTT     UHURA      4\n",
       "159    TAS     SPOCK     UHURA      4\n",
       "58     TAS    CHAPEL     SCOTT      3\n",
       "140    TAS     MCCOY     UHURA      3\n",
       "149    TAS     SCOTT     SPOCK      3\n",
       "110    TAS      KIRK     UHURA      2\n",
       "139    TAS     MCCOY      SULU      2\n",
       "55     TAS    CHAPEL     MCCOY      1"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_df.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f73f0140",
   "metadata": {},
   "outputs": [],
   "source": [
    "# exporting Star trek final data\n",
    "filtered_df.to_csv(os.path.join(path,'StarTrek_interaction_maincast_tas.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "20f6b10f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Character  Total_Count\n",
      "0      KIRK         23.0\n",
      "1     SPOCK         33.0\n",
      "2      SULU         20.0\n",
      "3     MCCOY         20.0\n",
      "4     SCOTT         22.0\n",
      "5    CHAPEL          4.0\n",
      "6     UHURA         20.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = filtered_df\n",
    "\n",
    "# Replace 'Dialogue1', 'Dialogue2', and 'Count' with the actual column names in your dataset\n",
    "\n",
    "# Create a list of all characters from both 'Dialogue1' and 'Dialogue2'\n",
    "all_characters = pd.concat([df['Dialogue1'], df['Dialogue2']]).unique()\n",
    "\n",
    "# Create a DataFrame with all characters\n",
    "all_characters_df = pd.DataFrame({'Character': all_characters})\n",
    "\n",
    "# Merge the DataFrame with counts for 'Dialogue1'\n",
    "all_characters_df = pd.merge(all_characters_df, df.groupby('Dialogue1')['Count'].sum().reset_index(), how='left', left_on='Character', right_on='Dialogue1').rename(columns={'Count': 'Count_Dialogue1'})\n",
    "\n",
    "# Merge the DataFrame with counts for 'Dialogue2'\n",
    "all_characters_df = pd.merge(all_characters_df, df.groupby('Dialogue2')['Count'].sum().reset_index(), how='left', left_on='Character', right_on='Dialogue2').rename(columns={'Count': 'Count_Dialogue2'})\n",
    "\n",
    "# Fill NaN values with 0\n",
    "all_characters_df['Count_Dialogue1'] = all_characters_df['Count_Dialogue1'].fillna(0)\n",
    "all_characters_df['Count_Dialogue2'] = all_characters_df['Count_Dialogue2'].fillna(0)\n",
    "\n",
    "# Calculate the total count\n",
    "all_characters_df['Total_Count'] = all_characters_df['Count_Dialogue1'] + all_characters_df['Count_Dialogue2']\n",
    "\n",
    "# Drop unnecessary columns\n",
    "all_characters_df = all_characters_df[['Character', 'Total_Count']]\n",
    "\n",
    "# Now, all_characters_df contains a list of characters and their total counts from both 'Dialogue1' and 'Dialogue2'\n",
    "print(all_characters_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ac9e1e8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# exporting Star trek tos total count data\n",
    "all_characters_df.to_csv(os.path.join(path,'StarTrek_total_count_interaction_maincast_tas.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01ef96b8",
   "metadata": {},
   "source": [
    "## TNG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "786e5172",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Series                              Dialogue1  \\\n",
      "1376    TNG                                 PICARD   \n",
      "1472    TNG                                  RIKER   \n",
      "683     TNG                                   DATA   \n",
      "677     TNG                                   DATA   \n",
      "658     TNG                                   DATA   \n",
      "...     ...                                    ...   \n",
      "1583    TNG                                 WESLEY   \n",
      "1584    TNG  WESLEY: No! He's very weak. TRAVELLER   \n",
      "1585    TNG                                  WOMAN   \n",
      "1587    TNG                                   WORF   \n",
      "1588    TNG                              YOUNG MAN   \n",
      "\n",
      "                                              Dialogue2  Count  \n",
      "1376                                              RIKER     57  \n",
      "1472                                               WORF     52  \n",
      "683                                               RIKER     48  \n",
      "677                                              PICARD     47  \n",
      "658                                             LAFORGE     42  \n",
      "...                                                 ...    ...  \n",
      "1583                                           ZERO ONE      1  \n",
      "1584  WESLEY: Parts of him disappeared and then came...      1  \n",
      "1585                                            WOMAN 2      1  \n",
      "1587                                             YRANAC      1  \n",
      "1588                                        YOUNG WOMAN      1  \n",
      "\n",
      "[1589 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "def extract_and_filter_interactions(json_file_path, specific_series, lines_threshold=2):\n",
    "    # Read data from the JSON file\n",
    "    with open(json_file_path, 'r') as file:\n",
    "        json_data = json.load(file)\n",
    "    # Extract interactions with series and episode information\n",
    "    interactions = []\n",
    "    for series_key, series_data in json_data.items():\n",
    "        if series_key == specific_series:\n",
    "            for character, dialogues in series_data.items():\n",
    "                # Ensure there are at least two dialogues for each character\n",
    "                if len(dialogues) >= lines_threshold:\n",
    "                    # Convert dialogues to strings\n",
    "                    dialogues = [str(dialogue) for dialogue in dialogues]\n",
    "\n",
    "                    # Create pairs of consecutive dialogues with series information\n",
    "                    for i in range(len(dialogues) - 1):\n",
    "                        # Sort the dialogues to ensure consistent order\n",
    "                        sorted_dialogues = sorted([dialogues[i], dialogues[i + 1]])\n",
    "\n",
    "                        interaction = (series_key, sorted_dialogues[0], sorted_dialogues[1])\n",
    "                        interactions.append(interaction)\n",
    "\n",
    "    # Count occurrences of interactions\n",
    "    interaction_counts = Counter(interactions)\n",
    "\n",
    "    # Convert the result to a DataFrame\n",
    "    df = pd.DataFrame(list(interaction_counts.items()), columns=['Interaction', 'Count'])\n",
    "\n",
    "    # Split the 'Interaction' column into 'Series', 'Dialogue1', and 'Dialogue2'\n",
    "    df[['Series', 'Dialogue1', 'Dialogue2']] = pd.DataFrame(df['Interaction'].tolist(), index=df.index)\n",
    "\n",
    "    # Drop the original 'Interaction' column\n",
    "    df.drop(columns=['Interaction'], inplace=True)\n",
    "\n",
    "    # Reorder columns\n",
    "    df = df[['Series', 'Dialogue1', 'Dialogue2', 'Count']]\n",
    "\n",
    "    # Group by the combined dialogues and sum the counts\n",
    "    df_combined = df.groupby(['Series', 'Dialogue1', 'Dialogue2']).agg({'Count': 'sum'}).reset_index()\n",
    "\n",
    "    # Sort by series, interaction, and count in descending order\n",
    "    df_combined.sort_values(by=['Series', 'Count'], ascending=[True, False], inplace=True)\n",
    "\n",
    "    # Filter the DataFrame for a specific series\n",
    "    filtered_df = df_combined.loc[df_combined['Series'] == specific_series]\n",
    "\n",
    "    return filtered_df\n",
    "\n",
    "# Example usage with lines_threshold set to 3\n",
    "json_file_path = '/Users/mariamaske/Star Trek Analysis/Data/StarTrekDialogue.json'\n",
    "specific_series = 'TNG'\n",
    "lines_threshold = 5\n",
    "result_df = extract_and_filter_interactions(json_file_path, specific_series, lines_threshold)\n",
    "\n",
    "# Print the final result\n",
    "print(result_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e3fe88ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace 'Dialogue1', 'Dialogue2', and 'Count' with the actual column names in your dataset\n",
    "allowed_dialogue1_values = ['PICARD', 'RIKER', 'DATA', 'WORF', 'TROI', 'CRUSHER', 'LAFORGE', 'WESLEY']  # Replace with the specific values you're interested in for 'Dialogue1'\n",
    "allowed_dialogue2_values = ['PICARD', 'RIKER', 'DATA', 'WORF', 'TROI', 'CRUSHER', 'LAFORGE', 'WESLEY']  # Replace with the specific values you're interested in for 'Dialogue2'\n",
    "\n",
    "filtered_df = result_df[\n",
    "    (result_df['Dialogue1'].isin(allowed_dialogue1_values)) & \n",
    "    (result_df['Dialogue2'].isin(allowed_dialogue2_values)) & \n",
    "    (result_df['Count'] >= 1)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "07bfffab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Series</th>\n",
       "      <th>Dialogue1</th>\n",
       "      <th>Dialogue2</th>\n",
       "      <th>Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1376</th>\n",
       "      <td>TNG</td>\n",
       "      <td>PICARD</td>\n",
       "      <td>RIKER</td>\n",
       "      <td>57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1472</th>\n",
       "      <td>TNG</td>\n",
       "      <td>RIKER</td>\n",
       "      <td>WORF</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>683</th>\n",
       "      <td>TNG</td>\n",
       "      <td>DATA</td>\n",
       "      <td>RIKER</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>677</th>\n",
       "      <td>TNG</td>\n",
       "      <td>DATA</td>\n",
       "      <td>PICARD</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>658</th>\n",
       "      <td>TNG</td>\n",
       "      <td>DATA</td>\n",
       "      <td>LAFORGE</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1395</th>\n",
       "      <td>TNG</td>\n",
       "      <td>PICARD</td>\n",
       "      <td>WORF</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>699</th>\n",
       "      <td>TNG</td>\n",
       "      <td>DATA</td>\n",
       "      <td>WORF</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1121</th>\n",
       "      <td>TNG</td>\n",
       "      <td>LAFORGE</td>\n",
       "      <td>RIKER</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>607</th>\n",
       "      <td>TNG</td>\n",
       "      <td>CRUSHER</td>\n",
       "      <td>TROI</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1117</th>\n",
       "      <td>TNG</td>\n",
       "      <td>LAFORGE</td>\n",
       "      <td>PICARD</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1153</th>\n",
       "      <td>TNG</td>\n",
       "      <td>LAFORGE</td>\n",
       "      <td>WORF</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1390</th>\n",
       "      <td>TNG</td>\n",
       "      <td>PICARD</td>\n",
       "      <td>TROI</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1569</th>\n",
       "      <td>TNG</td>\n",
       "      <td>TROI</td>\n",
       "      <td>WORF</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>519</th>\n",
       "      <td>TNG</td>\n",
       "      <td>CRUSHER</td>\n",
       "      <td>DATA</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1467</th>\n",
       "      <td>TNG</td>\n",
       "      <td>RIKER</td>\n",
       "      <td>TROI</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>694</th>\n",
       "      <td>TNG</td>\n",
       "      <td>DATA</td>\n",
       "      <td>TROI</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>554</th>\n",
       "      <td>TNG</td>\n",
       "      <td>CRUSHER</td>\n",
       "      <td>LAFORGE</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>621</th>\n",
       "      <td>TNG</td>\n",
       "      <td>CRUSHER</td>\n",
       "      <td>WORF</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>578</th>\n",
       "      <td>TNG</td>\n",
       "      <td>CRUSHER</td>\n",
       "      <td>PICARD</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>589</th>\n",
       "      <td>TNG</td>\n",
       "      <td>CRUSHER</td>\n",
       "      <td>RIKER</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>697</th>\n",
       "      <td>TNG</td>\n",
       "      <td>DATA</td>\n",
       "      <td>WESLEY</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1144</th>\n",
       "      <td>TNG</td>\n",
       "      <td>LAFORGE</td>\n",
       "      <td>TROI</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1567</th>\n",
       "      <td>TNG</td>\n",
       "      <td>TROI</td>\n",
       "      <td>WESLEY</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1152</th>\n",
       "      <td>TNG</td>\n",
       "      <td>LAFORGE</td>\n",
       "      <td>WESLEY</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1470</th>\n",
       "      <td>TNG</td>\n",
       "      <td>RIKER</td>\n",
       "      <td>WESLEY</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1394</th>\n",
       "      <td>TNG</td>\n",
       "      <td>PICARD</td>\n",
       "      <td>WESLEY</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1581</th>\n",
       "      <td>TNG</td>\n",
       "      <td>WESLEY</td>\n",
       "      <td>WORF</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>617</th>\n",
       "      <td>TNG</td>\n",
       "      <td>CRUSHER</td>\n",
       "      <td>WESLEY</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Series Dialogue1 Dialogue2  Count\n",
       "1376    TNG    PICARD     RIKER     57\n",
       "1472    TNG     RIKER      WORF     52\n",
       "683     TNG      DATA     RIKER     48\n",
       "677     TNG      DATA    PICARD     47\n",
       "658     TNG      DATA   LAFORGE     42\n",
       "1395    TNG    PICARD      WORF     34\n",
       "699     TNG      DATA      WORF     30\n",
       "1121    TNG   LAFORGE     RIKER     30\n",
       "607     TNG   CRUSHER      TROI     27\n",
       "1117    TNG   LAFORGE    PICARD     27\n",
       "1153    TNG   LAFORGE      WORF     27\n",
       "1390    TNG    PICARD      TROI     24\n",
       "1569    TNG      TROI      WORF     24\n",
       "519     TNG   CRUSHER      DATA     23\n",
       "1467    TNG     RIKER      TROI     23\n",
       "694     TNG      DATA      TROI     22\n",
       "554     TNG   CRUSHER   LAFORGE     17\n",
       "621     TNG   CRUSHER      WORF     17\n",
       "578     TNG   CRUSHER    PICARD     15\n",
       "589     TNG   CRUSHER     RIKER     15\n",
       "697     TNG      DATA    WESLEY     15\n",
       "1144    TNG   LAFORGE      TROI     13\n",
       "1567    TNG      TROI    WESLEY     13\n",
       "1152    TNG   LAFORGE    WESLEY     11\n",
       "1470    TNG     RIKER    WESLEY     11\n",
       "1394    TNG    PICARD    WESLEY     10\n",
       "1581    TNG    WESLEY      WORF     10\n",
       "617     TNG   CRUSHER    WESLEY      9"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_df.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "866b983f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# exporting Star trek final data\n",
    "filtered_df.to_csv(os.path.join(path,'StarTrek_interaction_maincast_tng.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8da644af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Character  Total_Count\n",
      "0    PICARD        214.0\n",
      "1     RIKER        236.0\n",
      "2      DATA        227.0\n",
      "3   LAFORGE        167.0\n",
      "4   CRUSHER        123.0\n",
      "5      TROI        146.0\n",
      "6    WESLEY         79.0\n",
      "7      WORF        194.0\n"
     ]
    }
   ],
   "source": [
    "df = filtered_df\n",
    "\n",
    "# Replace 'Dialogue1', 'Dialogue2', and 'Count' with the actual column names in your dataset\n",
    "\n",
    "# Create a list of all characters from both 'Dialogue1' and 'Dialogue2'\n",
    "all_characters = pd.concat([df['Dialogue1'], df['Dialogue2']]).unique()\n",
    "\n",
    "# Create a DataFrame with all characters\n",
    "all_characters_df = pd.DataFrame({'Character': all_characters})\n",
    "\n",
    "# Merge the DataFrame with counts for 'Dialogue1'\n",
    "all_characters_df = pd.merge(all_characters_df, df.groupby('Dialogue1')['Count'].sum().reset_index(), how='left', left_on='Character', right_on='Dialogue1').rename(columns={'Count': 'Count_Dialogue1'})\n",
    "\n",
    "# Merge the DataFrame with counts for 'Dialogue2'\n",
    "all_characters_df = pd.merge(all_characters_df, df.groupby('Dialogue2')['Count'].sum().reset_index(), how='left', left_on='Character', right_on='Dialogue2').rename(columns={'Count': 'Count_Dialogue2'})\n",
    "\n",
    "# Fill NaN values with 0\n",
    "all_characters_df['Count_Dialogue1'] = all_characters_df['Count_Dialogue1'].fillna(0)\n",
    "all_characters_df['Count_Dialogue2'] = all_characters_df['Count_Dialogue2'].fillna(0)\n",
    "\n",
    "# Calculate the total count\n",
    "all_characters_df['Total_Count'] = all_characters_df['Count_Dialogue1'] + all_characters_df['Count_Dialogue2']\n",
    "\n",
    "# Drop unnecessary columns\n",
    "all_characters_df = all_characters_df[['Character', 'Total_Count']]\n",
    "\n",
    "# Now, all_characters_df contains a list of characters and their total counts from both 'Dialogue1' and 'Dialogue2'\n",
    "print(all_characters_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dd7d5052",
   "metadata": {},
   "outputs": [],
   "source": [
    "# exporting Star trek tos total count data\n",
    "all_characters_df.to_csv(os.path.join(path,'StarTrek_total_count_interaction_maincast_tng.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "693c1a08",
   "metadata": {},
   "source": [
    "## DS9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a341ac7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Series Dialogue1      Dialogue2  Count\n",
      "1123    DS9      KIRA          SISKO     50\n",
      "204     DS9    BASHIR        O'BRIEN     45\n",
      "615     DS9       DAX           KIRA     45\n",
      "1399    DS9       ODO          QUARK     41\n",
      "1109    DS9      KIRA        O'BRIEN     33\n",
      "...     ...       ...            ...    ...\n",
      "1605    DS9    WEYOUN           WORF      1\n",
      "1606    DS9   WHATLEY           WORF      1\n",
      "1607    DS9    WILLIE          WOMAN      1\n",
      "1608    DS9     WOMAN        WOMAN 2      1\n",
      "1609    DS9      WORF  WORF + HURAGA      1\n",
      "\n",
      "[1611 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "def extract_and_filter_interactions(json_file_path, specific_series, lines_threshold=2):\n",
    "    # Read data from the JSON file\n",
    "    with open(json_file_path, 'r') as file:\n",
    "        json_data = json.load(file)\n",
    "    # Extract interactions with series and episode information\n",
    "    interactions = []\n",
    "    for series_key, series_data in json_data.items():\n",
    "        if series_key == specific_series:\n",
    "            for character, dialogues in series_data.items():\n",
    "                # Ensure there are at least two dialogues for each character\n",
    "                if len(dialogues) >= lines_threshold:\n",
    "                    # Convert dialogues to strings\n",
    "                    dialogues = [str(dialogue) for dialogue in dialogues]\n",
    "\n",
    "                    # Create pairs of consecutive dialogues with series information\n",
    "                    for i in range(len(dialogues) - 1):\n",
    "                        # Sort the dialogues to ensure consistent order\n",
    "                        sorted_dialogues = sorted([dialogues[i], dialogues[i + 1]])\n",
    "\n",
    "                        interaction = (series_key, sorted_dialogues[0], sorted_dialogues[1])\n",
    "                        interactions.append(interaction)\n",
    "\n",
    "    # Count occurrences of interactions\n",
    "    interaction_counts = Counter(interactions)\n",
    "\n",
    "    # Convert the result to a DataFrame\n",
    "    df = pd.DataFrame(list(interaction_counts.items()), columns=['Interaction', 'Count'])\n",
    "\n",
    "    # Split the 'Interaction' column into 'Series', 'Dialogue1', and 'Dialogue2'\n",
    "    df[['Series', 'Dialogue1', 'Dialogue2']] = pd.DataFrame(df['Interaction'].tolist(), index=df.index)\n",
    "\n",
    "    # Drop the original 'Interaction' column\n",
    "    df.drop(columns=['Interaction'], inplace=True)\n",
    "\n",
    "    # Reorder columns\n",
    "    df = df[['Series', 'Dialogue1', 'Dialogue2', 'Count']]\n",
    "\n",
    "    # Group by the combined dialogues and sum the counts\n",
    "    df_combined = df.groupby(['Series', 'Dialogue1', 'Dialogue2']).agg({'Count': 'sum'}).reset_index()\n",
    "\n",
    "    # Sort by series, interaction, and count in descending order\n",
    "    df_combined.sort_values(by=['Series', 'Count'], ascending=[True, False], inplace=True)\n",
    "\n",
    "    # Filter the DataFrame for a specific series\n",
    "    filtered_df = df_combined.loc[df_combined['Series'] == specific_series]\n",
    "\n",
    "    return filtered_df\n",
    "\n",
    "# Example usage with lines_threshold set to 3\n",
    "json_file_path = '/Users/mariamaske/Star Trek Analysis/Data/StarTrekDialogue.json'\n",
    "specific_series = 'DS9'\n",
    "lines_threshold = 5\n",
    "result_df = extract_and_filter_interactions(json_file_path, specific_series, lines_threshold)\n",
    "\n",
    "# Print the final result\n",
    "print(result_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "681d8955",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace 'Dialogue1', 'Dialogue2', and 'Count' with the actual column names in your dataset\n",
    "allowed_dialogue1_values = ['SISKO', 'ODO', 'DAX', 'KIRA', \"O'BRIEN\", 'QUARK', 'BASHIR', 'JAKE', 'WORF', 'EZRI']  # Replace with the specific values you're interested in for 'Dialogue1'\n",
    "allowed_dialogue2_values = ['SISKO', 'ODO', 'DAX', 'KIRA', \"O'BRIEN\", 'QUARK', 'BASHIR', 'JAKE', 'WORF', 'EZRI']  # Replace with the specific values you're interested in for 'Dialogue2'\n",
    "\n",
    "filtered_df = result_df[\n",
    "    (result_df['Dialogue1'].isin(allowed_dialogue1_values)) & \n",
    "    (result_df['Dialogue2'].isin(allowed_dialogue2_values)) & \n",
    "    (result_df['Count'] >= 5)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c7937cc1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Series</th>\n",
       "      <th>Dialogue1</th>\n",
       "      <th>Dialogue2</th>\n",
       "      <th>Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1123</th>\n",
       "      <td>DS9</td>\n",
       "      <td>KIRA</td>\n",
       "      <td>SISKO</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204</th>\n",
       "      <td>DS9</td>\n",
       "      <td>BASHIR</td>\n",
       "      <td>O'BRIEN</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>615</th>\n",
       "      <td>DS9</td>\n",
       "      <td>DAX</td>\n",
       "      <td>KIRA</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1399</th>\n",
       "      <td>DS9</td>\n",
       "      <td>ODO</td>\n",
       "      <td>QUARK</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1109</th>\n",
       "      <td>DS9</td>\n",
       "      <td>KIRA</td>\n",
       "      <td>O'BRIEN</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>645</th>\n",
       "      <td>DS9</td>\n",
       "      <td>DAX</td>\n",
       "      <td>SISKO</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205</th>\n",
       "      <td>DS9</td>\n",
       "      <td>BASHIR</td>\n",
       "      <td>ODO</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>630</th>\n",
       "      <td>DS9</td>\n",
       "      <td>DAX</td>\n",
       "      <td>O'BRIEN</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1371</th>\n",
       "      <td>DS9</td>\n",
       "      <td>O'BRIEN</td>\n",
       "      <td>SISKO</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>DS9</td>\n",
       "      <td>BASHIR</td>\n",
       "      <td>DAX</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1110</th>\n",
       "      <td>DS9</td>\n",
       "      <td>KIRA</td>\n",
       "      <td>ODO</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183</th>\n",
       "      <td>DS9</td>\n",
       "      <td>BASHIR</td>\n",
       "      <td>KIRA</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>634</th>\n",
       "      <td>DS9</td>\n",
       "      <td>DAX</td>\n",
       "      <td>QUARK</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1360</th>\n",
       "      <td>DS9</td>\n",
       "      <td>O'BRIEN</td>\n",
       "      <td>ODO</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>652</th>\n",
       "      <td>DS9</td>\n",
       "      <td>DAX</td>\n",
       "      <td>WORF</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>213</th>\n",
       "      <td>DS9</td>\n",
       "      <td>BASHIR</td>\n",
       "      <td>SISKO</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1414</th>\n",
       "      <td>DS9</td>\n",
       "      <td>ODO</td>\n",
       "      <td>SISKO</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1003</th>\n",
       "      <td>DS9</td>\n",
       "      <td>JAKE</td>\n",
       "      <td>SISKO</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1133</th>\n",
       "      <td>DS9</td>\n",
       "      <td>KIRA</td>\n",
       "      <td>WORF</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1382</th>\n",
       "      <td>DS9</td>\n",
       "      <td>O'BRIEN</td>\n",
       "      <td>WORF</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>632</th>\n",
       "      <td>DS9</td>\n",
       "      <td>DAX</td>\n",
       "      <td>ODO</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210</th>\n",
       "      <td>DS9</td>\n",
       "      <td>BASHIR</td>\n",
       "      <td>QUARK</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>227</th>\n",
       "      <td>DS9</td>\n",
       "      <td>BASHIR</td>\n",
       "      <td>WORF</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1361</th>\n",
       "      <td>DS9</td>\n",
       "      <td>O'BRIEN</td>\n",
       "      <td>QUARK</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1115</th>\n",
       "      <td>DS9</td>\n",
       "      <td>KIRA</td>\n",
       "      <td>QUARK</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1567</th>\n",
       "      <td>DS9</td>\n",
       "      <td>SISKO</td>\n",
       "      <td>WORF</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>979</th>\n",
       "      <td>DS9</td>\n",
       "      <td>JAKE</td>\n",
       "      <td>KIRA</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>DS9</td>\n",
       "      <td>JAKE</td>\n",
       "      <td>QUARK</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>994</th>\n",
       "      <td>DS9</td>\n",
       "      <td>JAKE</td>\n",
       "      <td>ODO</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1499</th>\n",
       "      <td>DS9</td>\n",
       "      <td>QUARK</td>\n",
       "      <td>WORF</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1427</th>\n",
       "      <td>DS9</td>\n",
       "      <td>ODO</td>\n",
       "      <td>WORF</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1484</th>\n",
       "      <td>DS9</td>\n",
       "      <td>QUARK</td>\n",
       "      <td>SISKO</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>DS9</td>\n",
       "      <td>BASHIR</td>\n",
       "      <td>JAKE</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>DS9</td>\n",
       "      <td>BASHIR</td>\n",
       "      <td>EZRI</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>772</th>\n",
       "      <td>DS9</td>\n",
       "      <td>EZRI</td>\n",
       "      <td>WORF</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>992</th>\n",
       "      <td>DS9</td>\n",
       "      <td>JAKE</td>\n",
       "      <td>O'BRIEN</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Series Dialogue1 Dialogue2  Count\n",
       "1123    DS9      KIRA     SISKO     50\n",
       "204     DS9    BASHIR   O'BRIEN     45\n",
       "615     DS9       DAX      KIRA     45\n",
       "1399    DS9       ODO     QUARK     41\n",
       "1109    DS9      KIRA   O'BRIEN     33\n",
       "645     DS9       DAX     SISKO     31\n",
       "205     DS9    BASHIR       ODO     30\n",
       "630     DS9       DAX   O'BRIEN     29\n",
       "1371    DS9   O'BRIEN     SISKO     29\n",
       "156     DS9    BASHIR       DAX     28\n",
       "1110    DS9      KIRA       ODO     28\n",
       "183     DS9    BASHIR      KIRA     25\n",
       "634     DS9       DAX     QUARK     23\n",
       "1360    DS9   O'BRIEN       ODO     23\n",
       "652     DS9       DAX      WORF     22\n",
       "213     DS9    BASHIR     SISKO     19\n",
       "1414    DS9       ODO     SISKO     19\n",
       "1003    DS9      JAKE     SISKO     18\n",
       "1133    DS9      KIRA      WORF     18\n",
       "1382    DS9   O'BRIEN      WORF     18\n",
       "632     DS9       DAX       ODO     17\n",
       "210     DS9    BASHIR     QUARK     16\n",
       "227     DS9    BASHIR      WORF     16\n",
       "1361    DS9   O'BRIEN     QUARK     15\n",
       "1115    DS9      KIRA     QUARK     14\n",
       "1567    DS9     SISKO      WORF     13\n",
       "979     DS9      JAKE      KIRA     11\n",
       "998     DS9      JAKE     QUARK     11\n",
       "994     DS9      JAKE       ODO     10\n",
       "1499    DS9     QUARK      WORF     10\n",
       "1427    DS9       ODO      WORF      9\n",
       "1484    DS9     QUARK     SISKO      9\n",
       "176     DS9    BASHIR      JAKE      6\n",
       "164     DS9    BASHIR      EZRI      5\n",
       "772     DS9      EZRI      WORF      5\n",
       "992     DS9      JAKE   O'BRIEN      5"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_df.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a8da1013",
   "metadata": {},
   "outputs": [],
   "source": [
    "# exporting Star trek final data\n",
    "filtered_df.to_csv(os.path.join(path,'StarTrek_interaction_maincast_ds9.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9673a30e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Character  Total_Count\n",
      "0      KIRA        224.0\n",
      "1    BASHIR        190.0\n",
      "2       DAX        195.0\n",
      "3       ODO        177.0\n",
      "4   O'BRIEN        197.0\n",
      "5      JAKE         61.0\n",
      "6     SISKO        188.0\n",
      "7     QUARK        139.0\n",
      "8      EZRI         10.0\n",
      "9      WORF        111.0\n"
     ]
    }
   ],
   "source": [
    "df = filtered_df\n",
    "\n",
    "# Replace 'Dialogue1', 'Dialogue2', and 'Count' with the actual column names in your dataset\n",
    "\n",
    "# Create a list of all characters from both 'Dialogue1' and 'Dialogue2'\n",
    "all_characters = pd.concat([df['Dialogue1'], df['Dialogue2']]).unique()\n",
    "\n",
    "# Create a DataFrame with all characters\n",
    "all_characters_df = pd.DataFrame({'Character': all_characters})\n",
    "\n",
    "# Merge the DataFrame with counts for 'Dialogue1'\n",
    "all_characters_df = pd.merge(all_characters_df, df.groupby('Dialogue1')['Count'].sum().reset_index(), how='left', left_on='Character', right_on='Dialogue1').rename(columns={'Count': 'Count_Dialogue1'})\n",
    "\n",
    "# Merge the DataFrame with counts for 'Dialogue2'\n",
    "all_characters_df = pd.merge(all_characters_df, df.groupby('Dialogue2')['Count'].sum().reset_index(), how='left', left_on='Character', right_on='Dialogue2').rename(columns={'Count': 'Count_Dialogue2'})\n",
    "\n",
    "# Fill NaN values with 0\n",
    "all_characters_df['Count_Dialogue1'] = all_characters_df['Count_Dialogue1'].fillna(0)\n",
    "all_characters_df['Count_Dialogue2'] = all_characters_df['Count_Dialogue2'].fillna(0)\n",
    "\n",
    "# Calculate the total count\n",
    "all_characters_df['Total_Count'] = all_characters_df['Count_Dialogue1'] + all_characters_df['Count_Dialogue2']\n",
    "\n",
    "# Drop unnecessary columns\n",
    "all_characters_df = all_characters_df[['Character', 'Total_Count']]\n",
    "\n",
    "# Now, all_characters_df contains a list of characters and their total counts from both 'Dialogue1' and 'Dialogue2'\n",
    "print(all_characters_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cf9a16fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# exporting Star trek tos total count data\n",
    "all_characters_df.to_csv(os.path.join(path,'StarTrek_total_count_interaction_maincast_ds9.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c37e36f",
   "metadata": {},
   "source": [
    "## ENT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6f7e2b97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Series Dialogue1                                          Dialogue2  Count\n",
      "108    ENT    ARCHER                                              T'POL     40\n",
      "498    ENT     HOSHI                                               REED     32\n",
      "113    ENT    ARCHER                                             TUCKER     31\n",
      "766    ENT      REED                                             TRAVIS     31\n",
      "831    ENT     T'POL                                             TUCKER     25\n",
      "..     ...       ...                                                ...    ...\n",
      "864    ENT   VALDORE                                               VRAX      1\n",
      "866    ENT    VOICES                                          YOUNG MAN      1\n",
      "867    ENT      VOSK  VOSK: You are a fool. You think we're equals b...      1\n",
      "868    ENT     YOLEN                                              ZEPHT      1\n",
      "869    ENT  ZHO'KAAN                                             ZSHAAR      1\n",
      "\n",
      "[870 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "def extract_and_filter_interactions(json_file_path, specific_series, lines_threshold=2):\n",
    "    # Read data from the JSON file\n",
    "    with open(json_file_path, 'r') as file:\n",
    "        json_data = json.load(file)\n",
    "    # Extract interactions with series and episode information\n",
    "    interactions = []\n",
    "    for series_key, series_data in json_data.items():\n",
    "        if series_key == specific_series:\n",
    "            for character, dialogues in series_data.items():\n",
    "                # Ensure there are at least two dialogues for each character\n",
    "                if len(dialogues) >= lines_threshold:\n",
    "                    # Convert dialogues to strings\n",
    "                    dialogues = [str(dialogue) for dialogue in dialogues]\n",
    "\n",
    "                    # Create pairs of consecutive dialogues with series information\n",
    "                    for i in range(len(dialogues) - 1):\n",
    "                        # Sort the dialogues to ensure consistent order\n",
    "                        sorted_dialogues = sorted([dialogues[i], dialogues[i + 1]])\n",
    "\n",
    "                        interaction = (series_key, sorted_dialogues[0], sorted_dialogues[1])\n",
    "                        interactions.append(interaction)\n",
    "\n",
    "    # Count occurrences of interactions\n",
    "    interaction_counts = Counter(interactions)\n",
    "\n",
    "    # Convert the result to a DataFrame\n",
    "    df = pd.DataFrame(list(interaction_counts.items()), columns=['Interaction', 'Count'])\n",
    "\n",
    "    # Split the 'Interaction' column into 'Series', 'Dialogue1', and 'Dialogue2'\n",
    "    df[['Series', 'Dialogue1', 'Dialogue2']] = pd.DataFrame(df['Interaction'].tolist(), index=df.index)\n",
    "\n",
    "    # Drop the original 'Interaction' column\n",
    "    df.drop(columns=['Interaction'], inplace=True)\n",
    "\n",
    "    # Reorder columns\n",
    "    df = df[['Series', 'Dialogue1', 'Dialogue2', 'Count']]\n",
    "\n",
    "    # Group by the combined dialogues and sum the counts\n",
    "    df_combined = df.groupby(['Series', 'Dialogue1', 'Dialogue2']).agg({'Count': 'sum'}).reset_index()\n",
    "\n",
    "    # Sort by series, interaction, and count in descending order\n",
    "    df_combined.sort_values(by=['Series', 'Count'], ascending=[True, False], inplace=True)\n",
    "\n",
    "    # Filter the DataFrame for a specific series\n",
    "    filtered_df = df_combined.loc[df_combined['Series'] == specific_series]\n",
    "\n",
    "    return filtered_df\n",
    "\n",
    "# Example usage with lines_threshold set to 3\n",
    "json_file_path = '/Users/mariamaske/Star Trek Analysis/Data/StarTrekDialogue.json'\n",
    "specific_series = 'ENT'\n",
    "lines_threshold = 5\n",
    "result_df = extract_and_filter_interactions(json_file_path, specific_series, lines_threshold)\n",
    "\n",
    "# Print the final result\n",
    "print(result_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4dfde1b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace 'Dialogue1', 'Dialogue2', and 'Count' with the actual column names in your dataset\n",
    "allowed_dialogue1_values = ['ARCHER', \"T'POL\", 'PHLOX', 'REES', \"TRAVIS\", 'HOSHI', 'TUCKER']  # Replace with the specific values you're interested in for 'Dialogue1'\n",
    "allowed_dialogue2_values = ['ARCHER', \"T'POL\", 'PHLOX', 'REES', \"TRAVIS\", 'HOSHI', 'TUCKER']  # Replace with the specific values you're interested in for 'Dialogue2'\n",
    "\n",
    "filtered_df = result_df[\n",
    "    (result_df['Dialogue1'].isin(allowed_dialogue1_values)) & \n",
    "    (result_df['Dialogue2'].isin(allowed_dialogue2_values)) & \n",
    "    (result_df['Count'] >= 5)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9a4f0770",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Series</th>\n",
       "      <th>Dialogue1</th>\n",
       "      <th>Dialogue2</th>\n",
       "      <th>Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>ENT</td>\n",
       "      <td>ARCHER</td>\n",
       "      <td>T'POL</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>ENT</td>\n",
       "      <td>ARCHER</td>\n",
       "      <td>TUCKER</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>831</th>\n",
       "      <td>ENT</td>\n",
       "      <td>T'POL</td>\n",
       "      <td>TUCKER</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>513</th>\n",
       "      <td>ENT</td>\n",
       "      <td>HOSHI</td>\n",
       "      <td>TRAVIS</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>721</th>\n",
       "      <td>ENT</td>\n",
       "      <td>PHLOX</td>\n",
       "      <td>TRAVIS</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>714</th>\n",
       "      <td>ENT</td>\n",
       "      <td>PHLOX</td>\n",
       "      <td>T'POL</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>509</th>\n",
       "      <td>ENT</td>\n",
       "      <td>HOSHI</td>\n",
       "      <td>T'POL</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>516</th>\n",
       "      <td>ENT</td>\n",
       "      <td>HOSHI</td>\n",
       "      <td>TUCKER</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>723</th>\n",
       "      <td>ENT</td>\n",
       "      <td>PHLOX</td>\n",
       "      <td>TUCKER</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>850</th>\n",
       "      <td>ENT</td>\n",
       "      <td>TRAVIS</td>\n",
       "      <td>TUCKER</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>ENT</td>\n",
       "      <td>ARCHER</td>\n",
       "      <td>HOSHI</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>494</th>\n",
       "      <td>ENT</td>\n",
       "      <td>HOSHI</td>\n",
       "      <td>PHLOX</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>830</th>\n",
       "      <td>ENT</td>\n",
       "      <td>T'POL</td>\n",
       "      <td>TRAVIS</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>ENT</td>\n",
       "      <td>ARCHER</td>\n",
       "      <td>PHLOX</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>ENT</td>\n",
       "      <td>ARCHER</td>\n",
       "      <td>TRAVIS</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Series Dialogue1 Dialogue2  Count\n",
       "108    ENT    ARCHER     T'POL     40\n",
       "113    ENT    ARCHER    TUCKER     31\n",
       "831    ENT     T'POL    TUCKER     25\n",
       "513    ENT     HOSHI    TRAVIS     21\n",
       "721    ENT     PHLOX    TRAVIS     19\n",
       "714    ENT     PHLOX     T'POL     16\n",
       "509    ENT     HOSHI     T'POL     15\n",
       "516    ENT     HOSHI    TUCKER     15\n",
       "723    ENT     PHLOX    TUCKER     15\n",
       "850    ENT    TRAVIS    TUCKER     15\n",
       "94     ENT    ARCHER     HOSHI     14\n",
       "494    ENT     HOSHI     PHLOX     14\n",
       "830    ENT     T'POL    TRAVIS     14\n",
       "99     ENT    ARCHER     PHLOX      7\n",
       "112    ENT    ARCHER    TRAVIS      5"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_df.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "07adbfc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# exporting Star trek final data\n",
    "filtered_df.to_csv(os.path.join(path,'StarTrek_interaction_maincast_ent.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ecf1e797",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Character  Total_Count\n",
      "0    ARCHER         97.0\n",
      "1     T'POL        110.0\n",
      "2     HOSHI         79.0\n",
      "3     PHLOX         71.0\n",
      "4    TRAVIS         74.0\n",
      "5    TUCKER        101.0\n"
     ]
    }
   ],
   "source": [
    "df = filtered_df\n",
    "\n",
    "# Replace 'Dialogue1', 'Dialogue2', and 'Count' with the actual column names in your dataset\n",
    "\n",
    "# Create a list of all characters from both 'Dialogue1' and 'Dialogue2'\n",
    "all_characters = pd.concat([df['Dialogue1'], df['Dialogue2']]).unique()\n",
    "\n",
    "# Create a DataFrame with all characters\n",
    "all_characters_df = pd.DataFrame({'Character': all_characters})\n",
    "\n",
    "# Merge the DataFrame with counts for 'Dialogue1'\n",
    "all_characters_df = pd.merge(all_characters_df, df.groupby('Dialogue1')['Count'].sum().reset_index(), how='left', left_on='Character', right_on='Dialogue1').rename(columns={'Count': 'Count_Dialogue1'})\n",
    "\n",
    "# Merge the DataFrame with counts for 'Dialogue2'\n",
    "all_characters_df = pd.merge(all_characters_df, df.groupby('Dialogue2')['Count'].sum().reset_index(), how='left', left_on='Character', right_on='Dialogue2').rename(columns={'Count': 'Count_Dialogue2'})\n",
    "\n",
    "# Fill NaN values with 0\n",
    "all_characters_df['Count_Dialogue1'] = all_characters_df['Count_Dialogue1'].fillna(0)\n",
    "all_characters_df['Count_Dialogue2'] = all_characters_df['Count_Dialogue2'].fillna(0)\n",
    "\n",
    "# Calculate the total count\n",
    "all_characters_df['Total_Count'] = all_characters_df['Count_Dialogue1'] + all_characters_df['Count_Dialogue2']\n",
    "\n",
    "# Drop unnecessary columns\n",
    "all_characters_df = all_characters_df[['Character', 'Total_Count']]\n",
    "\n",
    "# Now, all_characters_df contains a list of characters and their total counts from both 'Dialogue1' and 'Dialogue2'\n",
    "print(all_characters_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a2a5338f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# exporting Star trek tos total count data\n",
    "all_characters_df.to_csv(os.path.join(path,'StarTrek_total_count_interaction_maincast_ent.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aa323db",
   "metadata": {},
   "source": [
    "## DIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b2bdc63b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Series          Dialogue1      Dialogue2  Count\n",
      "360    DIS             DETMER       OWOSEKUN     13\n",
      "152    DIS              BRYCE       OWOSEKUN      9\n",
      "144    DIS              BRYCE         DETMER      8\n",
      "710    DIS            STAMETS          TILLY      8\n",
      "201    DIS            BURNHAM           SARU      7\n",
      "..     ...                ...            ...    ...\n",
      "726    DIS  TRANSPORTER CHIEF          TYLER      1\n",
      "727    DIS  TRANSPORTER CHIEF          WOMAN      1\n",
      "728    DIS              TYLER      VOQ-TYLER      1\n",
      "729    DIS              VANCE          WILLA      1\n",
      "730    DIS                VOQ  YOUNG T'KUVMA      1\n",
      "\n",
      "[731 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "def extract_and_filter_interactions(json_file_path, specific_series, lines_threshold=2):\n",
    "    # Read data from the JSON file\n",
    "    with open(json_file_path, 'r') as file:\n",
    "        json_data = json.load(file)\n",
    "    # Extract interactions with series and episode information\n",
    "    interactions = []\n",
    "    for series_key, series_data in json_data.items():\n",
    "        if series_key == specific_series:\n",
    "            for character, dialogues in series_data.items():\n",
    "                # Ensure there are at least two dialogues for each character\n",
    "                if len(dialogues) >= lines_threshold:\n",
    "                    # Convert dialogues to strings\n",
    "                    dialogues = [str(dialogue) for dialogue in dialogues]\n",
    "\n",
    "                    # Create pairs of consecutive dialogues with series information\n",
    "                    for i in range(len(dialogues) - 1):\n",
    "                        # Sort the dialogues to ensure consistent order\n",
    "                        sorted_dialogues = sorted([dialogues[i], dialogues[i + 1]])\n",
    "\n",
    "                        interaction = (series_key, sorted_dialogues[0], sorted_dialogues[1])\n",
    "                        interactions.append(interaction)\n",
    "\n",
    "    # Count occurrences of interactions\n",
    "    interaction_counts = Counter(interactions)\n",
    "\n",
    "    # Convert the result to a DataFrame\n",
    "    df = pd.DataFrame(list(interaction_counts.items()), columns=['Interaction', 'Count'])\n",
    "\n",
    "    # Split the 'Interaction' column into 'Series', 'Dialogue1', and 'Dialogue2'\n",
    "    df[['Series', 'Dialogue1', 'Dialogue2']] = pd.DataFrame(df['Interaction'].tolist(), index=df.index)\n",
    "\n",
    "    # Drop the original 'Interaction' column\n",
    "    df.drop(columns=['Interaction'], inplace=True)\n",
    "\n",
    "    # Reorder columns\n",
    "    df = df[['Series', 'Dialogue1', 'Dialogue2', 'Count']]\n",
    "\n",
    "    # Group by the combined dialogues and sum the counts\n",
    "    df_combined = df.groupby(['Series', 'Dialogue1', 'Dialogue2']).agg({'Count': 'sum'}).reset_index()\n",
    "\n",
    "    # Sort by series, interaction, and count in descending order\n",
    "    df_combined.sort_values(by=['Series', 'Count'], ascending=[True, False], inplace=True)\n",
    "\n",
    "    # Filter the DataFrame for a specific series\n",
    "    filtered_df = df_combined.loc[df_combined['Series'] == specific_series]\n",
    "\n",
    "    return filtered_df\n",
    "\n",
    "# Example usage with lines_threshold set to 3\n",
    "json_file_path = '/Users/mariamaske/Star Trek Analysis/Data/StarTrekDialogue.json'\n",
    "specific_series = 'DIS'\n",
    "lines_threshold = 5\n",
    "result_df = extract_and_filter_interactions(json_file_path, specific_series, lines_threshold)\n",
    "\n",
    "# Print the final result\n",
    "print(result_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0bf3ecb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace 'Dialogue1', 'Dialogue2', and 'Count' with the actual column names in your dataset\n",
    "allowed_dialogue1_values = ['BURNHAM', \"SARU\", 'TILLY', 'LORCA', \"CULBER\", 'PIKE', 'NHAN', 'STAMETS', 'TYLER']  # Replace with the specific values you're interested in for 'Dialogue1'\n",
    "allowed_dialogue2_values = ['BURNHAM', \"SARU\", 'TILLY', 'LORCA', \"CULBER\", 'PIKE', 'NHAN', 'STAMETS', 'TYLER']  # Replace with the specific values you're interested in for 'Dialogue2'\n",
    "\n",
    "filtered_df = result_df[\n",
    "    (result_df['Dialogue1'].isin(allowed_dialogue1_values)) & \n",
    "    (result_df['Dialogue2'].isin(allowed_dialogue2_values)) & \n",
    "    (result_df['Count'] >= 2)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3376f5f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Series</th>\n",
       "      <th>Dialogue1</th>\n",
       "      <th>Dialogue2</th>\n",
       "      <th>Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>710</th>\n",
       "      <td>DIS</td>\n",
       "      <td>STAMETS</td>\n",
       "      <td>TILLY</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <td>DIS</td>\n",
       "      <td>BURNHAM</td>\n",
       "      <td>SARU</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206</th>\n",
       "      <td>DIS</td>\n",
       "      <td>BURNHAM</td>\n",
       "      <td>TILLY</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>688</th>\n",
       "      <td>DIS</td>\n",
       "      <td>SARU</td>\n",
       "      <td>TILLY</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>685</th>\n",
       "      <td>DIS</td>\n",
       "      <td>SARU</td>\n",
       "      <td>STAMETS</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>DIS</td>\n",
       "      <td>BURNHAM</td>\n",
       "      <td>PIKE</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>337</th>\n",
       "      <td>DIS</td>\n",
       "      <td>CULBER</td>\n",
       "      <td>STAMETS</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>690</th>\n",
       "      <td>DIS</td>\n",
       "      <td>SARU</td>\n",
       "      <td>TYLER</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <td>DIS</td>\n",
       "      <td>BURNHAM</td>\n",
       "      <td>STAMETS</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>334</th>\n",
       "      <td>DIS</td>\n",
       "      <td>CULBER</td>\n",
       "      <td>SARU</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>339</th>\n",
       "      <td>DIS</td>\n",
       "      <td>CULBER</td>\n",
       "      <td>TILLY</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>637</th>\n",
       "      <td>DIS</td>\n",
       "      <td>PIKE</td>\n",
       "      <td>SARU</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>641</th>\n",
       "      <td>DIS</td>\n",
       "      <td>PIKE</td>\n",
       "      <td>TYLER</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186</th>\n",
       "      <td>DIS</td>\n",
       "      <td>BURNHAM</td>\n",
       "      <td>CULBER</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>208</th>\n",
       "      <td>DIS</td>\n",
       "      <td>BURNHAM</td>\n",
       "      <td>TYLER</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>341</th>\n",
       "      <td>DIS</td>\n",
       "      <td>CULBER</td>\n",
       "      <td>TYLER</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>526</th>\n",
       "      <td>DIS</td>\n",
       "      <td>LORCA</td>\n",
       "      <td>SARU</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>530</th>\n",
       "      <td>DIS</td>\n",
       "      <td>LORCA</td>\n",
       "      <td>TILLY</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>639</th>\n",
       "      <td>DIS</td>\n",
       "      <td>PIKE</td>\n",
       "      <td>TILLY</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>721</th>\n",
       "      <td>DIS</td>\n",
       "      <td>TILLY</td>\n",
       "      <td>TYLER</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Series Dialogue1 Dialogue2  Count\n",
       "710    DIS   STAMETS     TILLY      8\n",
       "201    DIS   BURNHAM      SARU      7\n",
       "206    DIS   BURNHAM     TILLY      7\n",
       "688    DIS      SARU     TILLY      7\n",
       "685    DIS      SARU   STAMETS      5\n",
       "197    DIS   BURNHAM      PIKE      4\n",
       "337    DIS    CULBER   STAMETS      4\n",
       "690    DIS      SARU     TYLER      4\n",
       "203    DIS   BURNHAM   STAMETS      3\n",
       "334    DIS    CULBER      SARU      3\n",
       "339    DIS    CULBER     TILLY      3\n",
       "637    DIS      PIKE      SARU      3\n",
       "641    DIS      PIKE     TYLER      3\n",
       "186    DIS   BURNHAM    CULBER      2\n",
       "208    DIS   BURNHAM     TYLER      2\n",
       "341    DIS    CULBER     TYLER      2\n",
       "526    DIS     LORCA      SARU      2\n",
       "530    DIS     LORCA     TILLY      2\n",
       "639    DIS      PIKE     TILLY      2\n",
       "721    DIS     TILLY     TYLER      2"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_df.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a5e37e8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# exporting Star trek final data\n",
    "filtered_df.to_csv(os.path.join(path,'StarTrek_interaction_maincast_dis.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e7db812b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Character  Total_Count\n",
      "0   STAMETS         20.0\n",
      "1   BURNHAM         25.0\n",
      "2      SARU         31.0\n",
      "3    CULBER         14.0\n",
      "4      PIKE         12.0\n",
      "5     LORCA          4.0\n",
      "6     TILLY         31.0\n",
      "7     TYLER         13.0\n"
     ]
    }
   ],
   "source": [
    "df = filtered_df\n",
    "\n",
    "# Replace 'Dialogue1', 'Dialogue2', and 'Count' with the actual column names in your dataset\n",
    "\n",
    "# Create a list of all characters from both 'Dialogue1' and 'Dialogue2'\n",
    "all_characters = pd.concat([df['Dialogue1'], df['Dialogue2']]).unique()\n",
    "\n",
    "# Create a DataFrame with all characters\n",
    "all_characters_df = pd.DataFrame({'Character': all_characters})\n",
    "\n",
    "# Merge the DataFrame with counts for 'Dialogue1'\n",
    "all_characters_df = pd.merge(all_characters_df, df.groupby('Dialogue1')['Count'].sum().reset_index(), how='left', left_on='Character', right_on='Dialogue1').rename(columns={'Count': 'Count_Dialogue1'})\n",
    "\n",
    "# Merge the DataFrame with counts for 'Dialogue2'\n",
    "all_characters_df = pd.merge(all_characters_df, df.groupby('Dialogue2')['Count'].sum().reset_index(), how='left', left_on='Character', right_on='Dialogue2').rename(columns={'Count': 'Count_Dialogue2'})\n",
    "\n",
    "# Fill NaN values with 0\n",
    "all_characters_df['Count_Dialogue1'] = all_characters_df['Count_Dialogue1'].fillna(0)\n",
    "all_characters_df['Count_Dialogue2'] = all_characters_df['Count_Dialogue2'].fillna(0)\n",
    "\n",
    "# Calculate the total count\n",
    "all_characters_df['Total_Count'] = all_characters_df['Count_Dialogue1'] + all_characters_df['Count_Dialogue2']\n",
    "\n",
    "# Drop unnecessary columns\n",
    "all_characters_df = all_characters_df[['Character', 'Total_Count']]\n",
    "\n",
    "# Now, all_characters_df contains a list of characters and their total counts from both 'Dialogue1' and 'Dialogue2'\n",
    "print(all_characters_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f3a622be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# exporting Star trek tos total count data\n",
    "all_characters_df.to_csv(os.path.join(path,'StarTrek_total_count_interaction_maincast_dis.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eef262e",
   "metadata": {},
   "source": [
    "## PIC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "233bacd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Series Dialogue1     Dialogue2  Count\n",
      "139    PIC     RAFFI          RIOS      4\n",
      "11     PIC     AGNES            OH      3\n",
      "63     PIC     ELNOR        PICARD      3\n",
      "123    PIC     NAREK          SOJI      3\n",
      "134    PIC    PICARD          RIOS      3\n",
      "..     ...       ...           ...    ...\n",
      "159    PIC      SOHI            XB      1\n",
      "160    PIC      SOJI  SOJI + RAFFI      1\n",
      "161    PIC      SOJI        TENQEM      1\n",
      "162    PIC     SOONG         SUTRA      1\n",
      "163    PIC    SYNTHS         WOMAN      1\n",
      "\n",
      "[164 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "def extract_and_filter_interactions(json_file_path, specific_series, lines_threshold=2):\n",
    "    # Read data from the JSON file\n",
    "    with open(json_file_path, 'r') as file:\n",
    "        json_data = json.load(file)\n",
    "    # Extract interactions with series and episode information\n",
    "    interactions = []\n",
    "    for series_key, series_data in json_data.items():\n",
    "        if series_key == specific_series:\n",
    "            for character, dialogues in series_data.items():\n",
    "                # Ensure there are at least two dialogues for each character\n",
    "                if len(dialogues) >= lines_threshold:\n",
    "                    # Convert dialogues to strings\n",
    "                    dialogues = [str(dialogue) for dialogue in dialogues]\n",
    "\n",
    "                    # Create pairs of consecutive dialogues with series information\n",
    "                    for i in range(len(dialogues) - 1):\n",
    "                        # Sort the dialogues to ensure consistent order\n",
    "                        sorted_dialogues = sorted([dialogues[i], dialogues[i + 1]])\n",
    "\n",
    "                        interaction = (series_key, sorted_dialogues[0], sorted_dialogues[1])\n",
    "                        interactions.append(interaction)\n",
    "\n",
    "    # Count occurrences of interactions\n",
    "    interaction_counts = Counter(interactions)\n",
    "\n",
    "    # Convert the result to a DataFrame\n",
    "    df = pd.DataFrame(list(interaction_counts.items()), columns=['Interaction', 'Count'])\n",
    "\n",
    "    # Split the 'Interaction' column into 'Series', 'Dialogue1', and 'Dialogue2'\n",
    "    df[['Series', 'Dialogue1', 'Dialogue2']] = pd.DataFrame(df['Interaction'].tolist(), index=df.index)\n",
    "\n",
    "    # Drop the original 'Interaction' column\n",
    "    df.drop(columns=['Interaction'], inplace=True)\n",
    "\n",
    "    # Reorder columns\n",
    "    df = df[['Series', 'Dialogue1', 'Dialogue2', 'Count']]\n",
    "\n",
    "    # Group by the combined dialogues and sum the counts\n",
    "    df_combined = df.groupby(['Series', 'Dialogue1', 'Dialogue2']).agg({'Count': 'sum'}).reset_index()\n",
    "\n",
    "    # Sort by series, interaction, and count in descending order\n",
    "    df_combined.sort_values(by=['Series', 'Count'], ascending=[True, False], inplace=True)\n",
    "\n",
    "    # Filter the DataFrame for a specific series\n",
    "    filtered_df = df_combined.loc[df_combined['Series'] == specific_series]\n",
    "\n",
    "    return filtered_df\n",
    "\n",
    "# Example usage with lines_threshold set to 3\n",
    "json_file_path = '/Users/mariamaske/Star Trek Analysis/Data/StarTrekDialogue.json'\n",
    "specific_series = 'PIC'\n",
    "lines_threshold = 5\n",
    "result_df = extract_and_filter_interactions(json_file_path, specific_series, lines_threshold)\n",
    "\n",
    "# Print the final result\n",
    "print(result_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2b63c0b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace 'Dialogue1', 'Dialogue2', and 'Count' with the actual column names in your dataset\n",
    "allowed_dialogue1_values = ['PICARD', \"AGNES\", 'SOJI', 'ELNOR', \"RIOS\", 'RAFFI']  # Replace with the specific values you're interested in for 'Dialogue1'\n",
    "allowed_dialogue2_values = ['PICARD', \"AGNES\", 'SOJI', 'ELNOR', \"RIOS\", 'RAFFI']  # Replace with the specific values you're interested in for 'Dialogue2'\n",
    "\n",
    "filtered_df = result_df[\n",
    "    (result_df['Dialogue1'].isin(allowed_dialogue1_values)) & \n",
    "    (result_df['Dialogue2'].isin(allowed_dialogue2_values)) & \n",
    "    (result_df['Count'] >= 1)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "31e26ddc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Series</th>\n",
       "      <th>Dialogue1</th>\n",
       "      <th>Dialogue2</th>\n",
       "      <th>Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>PIC</td>\n",
       "      <td>RAFFI</td>\n",
       "      <td>RIOS</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>PIC</td>\n",
       "      <td>ELNOR</td>\n",
       "      <td>PICARD</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>PIC</td>\n",
       "      <td>PICARD</td>\n",
       "      <td>RIOS</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>PIC</td>\n",
       "      <td>PICARD</td>\n",
       "      <td>SOJI</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>PIC</td>\n",
       "      <td>PICARD</td>\n",
       "      <td>RAFFI</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>PIC</td>\n",
       "      <td>RAFFI</td>\n",
       "      <td>SOJI</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>PIC</td>\n",
       "      <td>AGNES</td>\n",
       "      <td>PICARD</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>PIC</td>\n",
       "      <td>AGNES</td>\n",
       "      <td>RAFFI</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>PIC</td>\n",
       "      <td>AGNES</td>\n",
       "      <td>RIOS</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>PIC</td>\n",
       "      <td>ELNOR</td>\n",
       "      <td>RIOS</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>PIC</td>\n",
       "      <td>RIOS</td>\n",
       "      <td>SOJI</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Series Dialogue1 Dialogue2  Count\n",
       "139    PIC     RAFFI      RIOS      4\n",
       "63     PIC     ELNOR    PICARD      3\n",
       "134    PIC    PICARD      RIOS      3\n",
       "136    PIC    PICARD      SOJI      3\n",
       "133    PIC    PICARD     RAFFI      2\n",
       "141    PIC     RAFFI      SOJI      2\n",
       "12     PIC     AGNES    PICARD      1\n",
       "13     PIC     AGNES     RAFFI      1\n",
       "14     PIC     AGNES      RIOS      1\n",
       "64     PIC     ELNOR      RIOS      1\n",
       "151    PIC      RIOS      SOJI      1"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_df.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "34c2209c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# exporting Star trek final data\n",
    "filtered_df.to_csv(os.path.join(path,'StarTrek_interaction_maincast_pic.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "98a747d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Character  Total_Count\n",
      "0     RAFFI          9.0\n",
      "1     ELNOR          4.0\n",
      "2    PICARD         12.0\n",
      "3     AGNES          3.0\n",
      "4      RIOS         10.0\n",
      "5      SOJI          6.0\n"
     ]
    }
   ],
   "source": [
    "df = filtered_df\n",
    "\n",
    "# Replace 'Dialogue1', 'Dialogue2', and 'Count' with the actual column names in your dataset\n",
    "\n",
    "# Create a list of all characters from both 'Dialogue1' and 'Dialogue2'\n",
    "all_characters = pd.concat([df['Dialogue1'], df['Dialogue2']]).unique()\n",
    "\n",
    "# Create a DataFrame with all characters\n",
    "all_characters_df = pd.DataFrame({'Character': all_characters})\n",
    "\n",
    "# Merge the DataFrame with counts for 'Dialogue1'\n",
    "all_characters_df = pd.merge(all_characters_df, df.groupby('Dialogue1')['Count'].sum().reset_index(), how='left', left_on='Character', right_on='Dialogue1').rename(columns={'Count': 'Count_Dialogue1'})\n",
    "\n",
    "# Merge the DataFrame with counts for 'Dialogue2'\n",
    "all_characters_df = pd.merge(all_characters_df, df.groupby('Dialogue2')['Count'].sum().reset_index(), how='left', left_on='Character', right_on='Dialogue2').rename(columns={'Count': 'Count_Dialogue2'})\n",
    "\n",
    "# Fill NaN values with 0\n",
    "all_characters_df['Count_Dialogue1'] = all_characters_df['Count_Dialogue1'].fillna(0)\n",
    "all_characters_df['Count_Dialogue2'] = all_characters_df['Count_Dialogue2'].fillna(0)\n",
    "\n",
    "# Calculate the total count\n",
    "all_characters_df['Total_Count'] = all_characters_df['Count_Dialogue1'] + all_characters_df['Count_Dialogue2']\n",
    "\n",
    "# Drop unnecessary columns\n",
    "all_characters_df = all_characters_df[['Character', 'Total_Count']]\n",
    "\n",
    "# Now, all_characters_df contains a list of characters and their total counts from both 'Dialogue1' and 'Dialogue2'\n",
    "print(all_characters_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5d26fb90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# exporting Star trek tos total count data\n",
    "all_characters_df.to_csv(os.path.join(path,'StarTrek_total_count_interaction_maincast_pic.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ada2072",
   "metadata": {},
   "source": [
    "## VOY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "4a2a9db3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Series        Dialogue1      Dialogue2  Count\n",
      "1103    VOY              KIM          PARIS     50\n",
      "351     VOY         CHAKOTAY        JANEWAY     41\n",
      "388     VOY         CHAKOTAY          TUVOK     40\n",
      "966     VOY          JANEWAY            KIM     40\n",
      "991     VOY          JANEWAY          TUVOK     38\n",
      "...     ...              ...            ...    ...\n",
      "1443    VOY  ZAHL\\r OFFICIAL  ZAHL OFFICIAL      1\n",
      "1444    VOY        pCHAKOTAY           pEMH      1\n",
      "1445    VOY        pCHAKOTAY         pPARIS      1\n",
      "1446    VOY          pNEELIX         pTUVOK      1\n",
      "1447    VOY           pPARIS         pTUVOK      1\n",
      "\n",
      "[1448 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "def extract_and_filter_interactions(json_file_path, specific_series, lines_threshold=2):\n",
    "    # Read data from the JSON file\n",
    "    with open(json_file_path, 'r') as file:\n",
    "        json_data = json.load(file)\n",
    "    # Extract interactions with series and episode information\n",
    "    interactions = []\n",
    "    for series_key, series_data in json_data.items():\n",
    "        if series_key == specific_series:\n",
    "            for character, dialogues in series_data.items():\n",
    "                # Ensure there are at least two dialogues for each character\n",
    "                if len(dialogues) >= lines_threshold:\n",
    "                    # Convert dialogues to strings\n",
    "                    dialogues = [str(dialogue) for dialogue in dialogues]\n",
    "\n",
    "                    # Create pairs of consecutive dialogues with series information\n",
    "                    for i in range(len(dialogues) - 1):\n",
    "                        # Sort the dialogues to ensure consistent order\n",
    "                        sorted_dialogues = sorted([dialogues[i], dialogues[i + 1]])\n",
    "\n",
    "                        interaction = (series_key, sorted_dialogues[0], sorted_dialogues[1])\n",
    "                        interactions.append(interaction)\n",
    "\n",
    "    # Count occurrences of interactions\n",
    "    interaction_counts = Counter(interactions)\n",
    "\n",
    "    # Convert the result to a DataFrame\n",
    "    df = pd.DataFrame(list(interaction_counts.items()), columns=['Interaction', 'Count'])\n",
    "\n",
    "    # Split the 'Interaction' column into 'Series', 'Dialogue1', and 'Dialogue2'\n",
    "    df[['Series', 'Dialogue1', 'Dialogue2']] = pd.DataFrame(df['Interaction'].tolist(), index=df.index)\n",
    "\n",
    "    # Drop the original 'Interaction' column\n",
    "    df.drop(columns=['Interaction'], inplace=True)\n",
    "\n",
    "    # Reorder columns\n",
    "    df = df[['Series', 'Dialogue1', 'Dialogue2', 'Count']]\n",
    "\n",
    "    # Group by the combined dialogues and sum the counts\n",
    "    df_combined = df.groupby(['Series', 'Dialogue1', 'Dialogue2']).agg({'Count': 'sum'}).reset_index()\n",
    "\n",
    "    # Sort by series, interaction, and count in descending order\n",
    "    df_combined.sort_values(by=['Series', 'Count'], ascending=[True, False], inplace=True)\n",
    "\n",
    "    # Filter the DataFrame for a specific series\n",
    "    filtered_df = df_combined.loc[df_combined['Series'] == specific_series]\n",
    "\n",
    "    return filtered_df\n",
    "\n",
    "# Example usage with lines_threshold set to 3\n",
    "json_file_path = '/Users/mariamaske/Star Trek Analysis/Data/StarTrekDialogue.json'\n",
    "specific_series = 'VOY'\n",
    "lines_threshold = 5\n",
    "result_df = extract_and_filter_interactions(json_file_path, specific_series, lines_threshold)\n",
    "\n",
    "# Print the final result\n",
    "print(result_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "bf635757",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace 'Dialogue1', 'Dialogue2', and 'Count' with the actual column names in your dataset\n",
    "allowed_dialogue1_values = [\"SEVEN\", 'TORRES', 'JANEWAY', 'CHAKOTAY', 'NEELIX', 'PARIS', 'TUVOK', 'DOCTOR', 'KES', 'KIM']  # Replace with the specific values you're interested in for 'Dialogue1'\n",
    "allowed_dialogue2_values = [\"SEVEN\", 'TORRES', 'JANEWAY', 'CHAKOTAY', 'NEELIX', 'PARIS', 'TUVOK', 'DOCTOR', 'KES', 'KIM']  # Replace with the specific values you're interested in for 'Dialogue2'\n",
    "\n",
    "filtered_df = result_df[\n",
    "    (result_df['Dialogue1'].isin(allowed_dialogue1_values)) & \n",
    "    (result_df['Dialogue2'].isin(allowed_dialogue2_values)) & \n",
    "    (result_df['Count'] >= 1)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "adc06efd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Series</th>\n",
       "      <th>Dialogue1</th>\n",
       "      <th>Dialogue2</th>\n",
       "      <th>Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1103</th>\n",
       "      <td>VOY</td>\n",
       "      <td>KIM</td>\n",
       "      <td>PARIS</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>351</th>\n",
       "      <td>VOY</td>\n",
       "      <td>CHAKOTAY</td>\n",
       "      <td>JANEWAY</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>388</th>\n",
       "      <td>VOY</td>\n",
       "      <td>CHAKOTAY</td>\n",
       "      <td>TUVOK</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>966</th>\n",
       "      <td>VOY</td>\n",
       "      <td>JANEWAY</td>\n",
       "      <td>KIM</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>991</th>\n",
       "      <td>VOY</td>\n",
       "      <td>JANEWAY</td>\n",
       "      <td>TUVOK</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1119</th>\n",
       "      <td>VOY</td>\n",
       "      <td>KIM</td>\n",
       "      <td>TUVOK</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1329</th>\n",
       "      <td>VOY</td>\n",
       "      <td>PARIS</td>\n",
       "      <td>TUVOK</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>385</th>\n",
       "      <td>VOY</td>\n",
       "      <td>CHAKOTAY</td>\n",
       "      <td>TORRES</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>371</th>\n",
       "      <td>VOY</td>\n",
       "      <td>CHAKOTAY</td>\n",
       "      <td>PARIS</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>981</th>\n",
       "      <td>VOY</td>\n",
       "      <td>JANEWAY</td>\n",
       "      <td>PARIS</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>358</th>\n",
       "      <td>VOY</td>\n",
       "      <td>CHAKOTAY</td>\n",
       "      <td>KIM</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1328</th>\n",
       "      <td>VOY</td>\n",
       "      <td>PARIS</td>\n",
       "      <td>TORRES</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1421</th>\n",
       "      <td>VOY</td>\n",
       "      <td>TORRES</td>\n",
       "      <td>TUVOK</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1273</th>\n",
       "      <td>VOY</td>\n",
       "      <td>NEELIX</td>\n",
       "      <td>TORRES</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>377</th>\n",
       "      <td>VOY</td>\n",
       "      <td>CHAKOTAY</td>\n",
       "      <td>SEVEN</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>990</th>\n",
       "      <td>VOY</td>\n",
       "      <td>JANEWAY</td>\n",
       "      <td>TORRES</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1277</th>\n",
       "      <td>VOY</td>\n",
       "      <td>NEELIX</td>\n",
       "      <td>TUVOK</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1118</th>\n",
       "      <td>VOY</td>\n",
       "      <td>KIM</td>\n",
       "      <td>TORRES</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>367</th>\n",
       "      <td>VOY</td>\n",
       "      <td>CHAKOTAY</td>\n",
       "      <td>NEELIX</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>979</th>\n",
       "      <td>VOY</td>\n",
       "      <td>JANEWAY</td>\n",
       "      <td>NEELIX</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>987</th>\n",
       "      <td>VOY</td>\n",
       "      <td>JANEWAY</td>\n",
       "      <td>SEVEN</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1102</th>\n",
       "      <td>VOY</td>\n",
       "      <td>KIM</td>\n",
       "      <td>NEELIX</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1255</th>\n",
       "      <td>VOY</td>\n",
       "      <td>NEELIX</td>\n",
       "      <td>PARIS</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1111</th>\n",
       "      <td>VOY</td>\n",
       "      <td>KIM</td>\n",
       "      <td>SEVEN</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1389</th>\n",
       "      <td>VOY</td>\n",
       "      <td>SEVEN</td>\n",
       "      <td>TUVOK</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1267</th>\n",
       "      <td>VOY</td>\n",
       "      <td>NEELIX</td>\n",
       "      <td>SEVEN</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1388</th>\n",
       "      <td>VOY</td>\n",
       "      <td>SEVEN</td>\n",
       "      <td>TORRES</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1072</th>\n",
       "      <td>VOY</td>\n",
       "      <td>KES</td>\n",
       "      <td>NEELIX</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1073</th>\n",
       "      <td>VOY</td>\n",
       "      <td>KES</td>\n",
       "      <td>PARIS</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1081</th>\n",
       "      <td>VOY</td>\n",
       "      <td>KES</td>\n",
       "      <td>TUVOK</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1325</th>\n",
       "      <td>VOY</td>\n",
       "      <td>PARIS</td>\n",
       "      <td>SEVEN</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>357</th>\n",
       "      <td>VOY</td>\n",
       "      <td>CHAKOTAY</td>\n",
       "      <td>KES</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1080</th>\n",
       "      <td>VOY</td>\n",
       "      <td>KES</td>\n",
       "      <td>TORRES</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>965</th>\n",
       "      <td>VOY</td>\n",
       "      <td>JANEWAY</td>\n",
       "      <td>KES</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1066</th>\n",
       "      <td>VOY</td>\n",
       "      <td>KES</td>\n",
       "      <td>KIM</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>634</th>\n",
       "      <td>VOY</td>\n",
       "      <td>DOCTOR</td>\n",
       "      <td>KIM</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>636</th>\n",
       "      <td>VOY</td>\n",
       "      <td>DOCTOR</td>\n",
       "      <td>PARIS</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Series Dialogue1 Dialogue2  Count\n",
       "1103    VOY       KIM     PARIS     50\n",
       "351     VOY  CHAKOTAY   JANEWAY     41\n",
       "388     VOY  CHAKOTAY     TUVOK     40\n",
       "966     VOY   JANEWAY       KIM     40\n",
       "991     VOY   JANEWAY     TUVOK     38\n",
       "1119    VOY       KIM     TUVOK     37\n",
       "1329    VOY     PARIS     TUVOK     35\n",
       "385     VOY  CHAKOTAY    TORRES     32\n",
       "371     VOY  CHAKOTAY     PARIS     30\n",
       "981     VOY   JANEWAY     PARIS     30\n",
       "358     VOY  CHAKOTAY       KIM     29\n",
       "1328    VOY     PARIS    TORRES     27\n",
       "1421    VOY    TORRES     TUVOK     26\n",
       "1273    VOY    NEELIX    TORRES     25\n",
       "377     VOY  CHAKOTAY     SEVEN     23\n",
       "990     VOY   JANEWAY    TORRES     23\n",
       "1277    VOY    NEELIX     TUVOK     22\n",
       "1118    VOY       KIM    TORRES     21\n",
       "367     VOY  CHAKOTAY    NEELIX     18\n",
       "979     VOY   JANEWAY    NEELIX     18\n",
       "987     VOY   JANEWAY     SEVEN     18\n",
       "1102    VOY       KIM    NEELIX     18\n",
       "1255    VOY    NEELIX     PARIS     17\n",
       "1111    VOY       KIM     SEVEN     16\n",
       "1389    VOY     SEVEN     TUVOK     14\n",
       "1267    VOY    NEELIX     SEVEN     13\n",
       "1388    VOY     SEVEN    TORRES     13\n",
       "1072    VOY       KES    NEELIX     11\n",
       "1073    VOY       KES     PARIS     10\n",
       "1081    VOY       KES     TUVOK      9\n",
       "1325    VOY     PARIS     SEVEN      8\n",
       "357     VOY  CHAKOTAY       KES      7\n",
       "1080    VOY       KES    TORRES      5\n",
       "965     VOY   JANEWAY       KES      4\n",
       "1066    VOY       KES       KIM      3\n",
       "634     VOY    DOCTOR       KIM      1\n",
       "636     VOY    DOCTOR     PARIS      1"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_df.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "8dadcdd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# exporting Star trek final data\n",
    "filtered_df.to_csv(os.path.join(path,'StarTrek_interaction_maincast_voy.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "c4a5f6c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Character  Total_Count\n",
      "0       KIM        215.0\n",
      "1  CHAKOTAY        220.0\n",
      "2   JANEWAY        212.0\n",
      "3     PARIS        208.0\n",
      "4    TORRES        172.0\n",
      "5    NEELIX        142.0\n",
      "6     SEVEN        105.0\n",
      "7       KES         49.0\n",
      "8    DOCTOR          2.0\n",
      "9     TUVOK        221.0\n"
     ]
    }
   ],
   "source": [
    "df = filtered_df\n",
    "\n",
    "# Replace 'Dialogue1', 'Dialogue2', and 'Count' with the actual column names in your dataset\n",
    "\n",
    "# Create a list of all characters from both 'Dialogue1' and 'Dialogue2'\n",
    "all_characters = pd.concat([df['Dialogue1'], df['Dialogue2']]).unique()\n",
    "\n",
    "# Create a DataFrame with all characters\n",
    "all_characters_df = pd.DataFrame({'Character': all_characters})\n",
    "\n",
    "# Merge the DataFrame with counts for 'Dialogue1'\n",
    "all_characters_df = pd.merge(all_characters_df, df.groupby('Dialogue1')['Count'].sum().reset_index(), how='left', left_on='Character', right_on='Dialogue1').rename(columns={'Count': 'Count_Dialogue1'})\n",
    "\n",
    "# Merge the DataFrame with counts for 'Dialogue2'\n",
    "all_characters_df = pd.merge(all_characters_df, df.groupby('Dialogue2')['Count'].sum().reset_index(), how='left', left_on='Character', right_on='Dialogue2').rename(columns={'Count': 'Count_Dialogue2'})\n",
    "\n",
    "# Fill NaN values with 0\n",
    "all_characters_df['Count_Dialogue1'] = all_characters_df['Count_Dialogue1'].fillna(0)\n",
    "all_characters_df['Count_Dialogue2'] = all_characters_df['Count_Dialogue2'].fillna(0)\n",
    "\n",
    "# Calculate the total count\n",
    "all_characters_df['Total_Count'] = all_characters_df['Count_Dialogue1'] + all_characters_df['Count_Dialogue2']\n",
    "\n",
    "# Drop unnecessary columns\n",
    "all_characters_df = all_characters_df[['Character', 'Total_Count']]\n",
    "\n",
    "# Now, all_characters_df contains a list of characters and their total counts from both 'Dialogue1' and 'Dialogue2'\n",
    "print(all_characters_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "e08b7dd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# exporting Star trek tos total count data\n",
    "all_characters_df.to_csv(os.path.join(path,'StarTrek_total_count_interaction_maincast_voy.csv'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
